<!DOCTYPE html>
<html style="display: none;" lang="zh">
    <head>
    <meta charset="utf-8">
    <!--
        © Material Theme
        https://github.com/viosey/hexo-theme-material
        Version: 1.5.0 -->
    <script>
        window.materialVersion = "1.5.0"
        // Delete localstorage with these tags
        window.oldVersion = [
            'codestartv1',
            '1.3.4',
            '1.4.0',
            '1.4.0b1'
        ]
    </script>

    <!-- dns prefetch -->
    <meta http-equiv="x-dns-prefetch-control" content="on">





        <link rel="dns-prefetch" href="https://cdn-city.livere.com"/>










    <!-- Title -->
    
    <title>
        
            神经网络的简单理解 | 
        
        0x2a
    </title>

    <!-- Meta & Info -->
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="format-detection" content="telephone=no"/>
    <meta name="theme-color" content="#0097A7">
    <meta name="author" content="Steve">
    <meta name="description" itemprop="description" content="">
    <meta name="keywords" content=",算法,机器学习">

    <!-- Import lsloader -->
    <script>(function(){window.lsloader={jsRunSequence:[],jsnamemap:{},cssnamemap:{}};lsloader.removeLS=function(key){try{localStorage.removeItem(key)}catch(e){}};lsloader.setLS=function(key,val){try{localStorage.setItem(key,val)}catch(e){}};lsloader.getLS=function(key){var val="";try{val=localStorage.getItem(key)}catch(e){val=""}return val};versionString="/*"+(window.materialVersion||"unknownVersion")+"*/";lsloader.clean=function(){try{var keys=[];for(var i=0;i<localStorage.length;i++){keys.push(localStorage.key(i))}keys.forEach(function(key){var data=lsloader.getLS(key);if(window.oldVersion){var remove=window.oldVersion.reduce(function(p,c){return p||data.indexOf("/*"+c+"*/")!==-1},false);if(remove){lsloader.removeLS(key)}}})}catch(e){}};lsloader.clean();lsloader.load=function(jsname,jspath,cssonload,isJs){if(typeof cssonload==="boolean"){isJs=cssonload;cssonload=undefined}isJs=isJs||false;cssonload=cssonload||function(){};var code;code=this.getLS(jsname);if(code&&code.indexOf(versionString)===-1){this.removeLS(jsname);this.requestResource(jsname,jspath,cssonload,isJs);return}if(code){var versionNumber=code.split(versionString)[0];if(versionNumber!=jspath){console.log("reload:"+jspath);this.removeLS(jsname);this.requestResource(jsname,jspath,cssonload,isJs);return}code=code.split(versionString)[1];if(isJs){this.jsRunSequence.push({name:jsname,code:code});this.runjs(jspath,jsname,code)}else{document.getElementById(jsname).appendChild(document.createTextNode(code));cssonload()}}else{this.requestResource(jsname,jspath,cssonload,isJs)}};lsloader.requestResource=function(name,path,cssonload,isJs){var that=this;if(isJs){this.iojs(path,name,function(path,name,code){that.setLS(name,path+versionString+code);that.runjs(path,name,code)})}else{this.iocss(path,name,function(code){document.getElementById(name).appendChild(document.createTextNode(code));that.setLS(name,path+versionString+code)},cssonload)}};lsloader.iojs=function(path,jsname,callback){var that=this;that.jsRunSequence.push({name:jsname,code:""});try{var xhr=new XMLHttpRequest;xhr.open("get",path,true);xhr.onreadystatechange=function(){if(xhr.readyState==4){if(xhr.status>=200&&xhr.status<300||xhr.status==304){if(xhr.response!=""){callback(path,jsname,xhr.response);return}}that.jsfallback(path,jsname)}};xhr.send(null)}catch(e){that.jsfallback(path,jsname)}};lsloader.iocss=function(path,jsname,callback,cssonload){var that=this;try{var xhr=new XMLHttpRequest;xhr.open("get",path,true);xhr.onreadystatechange=function(){if(xhr.readyState==4){if(xhr.status>=200&&xhr.status<300||xhr.status==304){if(xhr.response!=""){callback(xhr.response);cssonload();return}}that.cssfallback(path,jsname,cssonload)}};xhr.send(null)}catch(e){that.cssfallback(path,jsname,cssonload)}};lsloader.iofonts=function(path,jsname,callback,cssonload){var that=this;try{var xhr=new XMLHttpRequest;xhr.open("get",path,true);xhr.onreadystatechange=function(){if(xhr.readyState==4){if(xhr.status>=200&&xhr.status<300||xhr.status==304){if(xhr.response!=""){callback(xhr.response);cssonload();return}}that.cssfallback(path,jsname,cssonload)}};xhr.send(null)}catch(e){that.cssfallback(path,jsname,cssonload)}};lsloader.runjs=function(path,name,code){if(!!name&&!!code){for(var k in this.jsRunSequence){if(this.jsRunSequence[k].name==name){this.jsRunSequence[k].code=code}}}if(!!this.jsRunSequence[0]&&!!this.jsRunSequence[0].code&&this.jsRunSequence[0].status!="failed"){var script=document.createElement("script");script.appendChild(document.createTextNode(this.jsRunSequence[0].code));script.type="text/javascript";document.getElementsByTagName("head")[0].appendChild(script);this.jsRunSequence.shift();if(this.jsRunSequence.length>0){this.runjs()}}else if(!!this.jsRunSequence[0]&&this.jsRunSequence[0].status=="failed"){var that=this;var script=document.createElement("script");script.src=this.jsRunSequence[0].path;script.type="text/javascript";this.jsRunSequence[0].status="loading";script.onload=function(){that.jsRunSequence.shift();if(that.jsRunSequence.length>0){that.runjs()}};document.body.appendChild(script)}};lsloader.tagLoad=function(path,name){this.jsRunSequence.push({name:name,code:"",path:path,status:"failed"});this.runjs()};lsloader.jsfallback=function(path,name){if(!!this.jsnamemap[name]){return}else{this.jsnamemap[name]=name}for(var k in this.jsRunSequence){if(this.jsRunSequence[k].name==name){this.jsRunSequence[k].code="";this.jsRunSequence[k].status="failed";this.jsRunSequence[k].path=path}}this.runjs()};lsloader.cssfallback=function(path,name,cssonload){if(!!this.cssnamemap[name]){return}else{this.cssnamemap[name]=1}var link=document.createElement("link");link.type="text/css";link.href=path;link.rel="stylesheet";link.onload=link.onerror=cssonload;var root=document.getElementsByTagName("script")[0];root.parentNode.insertBefore(link,root)};lsloader.runInlineScript=function(scriptId,codeId){var code=document.getElementById(codeId).innerText;this.jsRunSequence.push({name:scriptId,code:code});this.runjs()};lsloader.loadCombo=function(jslist){var updateList="";var requestingModules={};for(var k in jslist){var LS=this.getLS(jslist[k].name);if(!!LS){var version=LS.split(versionString)[0];var code=LS.split(versionString)[1]}else{var version=""}if(version==jslist[k].path){this.jsRunSequence.push({name:jslist[k].name,code:code,path:jslist[k].path})}else{this.jsRunSequence.push({name:jslist[k].name,code:null,path:jslist[k].path,status:"comboloading"});requestingModules[jslist[k].name]=true;updateList+=(updateList==""?"":";")+jslist[k].path}}var that=this;if(!!updateList){var xhr=new XMLHttpRequest;xhr.open("get",combo+updateList,true);xhr.onreadystatechange=function(){if(xhr.readyState==4){if(xhr.status>=200&&xhr.status<300||xhr.status==304){if(xhr.response!=""){that.runCombo(xhr.response,requestingModules);return}}else{for(var i in that.jsRunSequence){if(requestingModules[that.jsRunSequence[i].name]){that.jsRunSequence[i].status="failed"}}that.runjs()}}};xhr.send(null)}this.runjs()};lsloader.runCombo=function(comboCode,requestingModules){comboCode=comboCode.split("/*combojs*/");comboCode.shift();for(var k in this.jsRunSequence){if(!!requestingModules[this.jsRunSequence[k].name]&&!!comboCode[0]){this.jsRunSequence[k].status="comboJS";this.jsRunSequence[k].code=comboCode[0];this.setLS(this.jsRunSequence[k].name,this.jsRunSequence[k].path+versionString+comboCode[0]);comboCode.shift()}}this.runjs()}})();</script>

    <!-- Import queue -->
    <script>function Queue(){this.dataStore=[];this.offer=b;this.poll=d;this.execNext=a;this.debug=false;this.startDebug=c;function b(e){if(this.debug){console.log("Offered a Queued Function.")}if(typeof e==="function"){this.dataStore.push(e)}else{console.log("You must offer a function.")}}function d(){if(this.debug){console.log("Polled a Queued Function.")}return this.dataStore.shift()}function a(){var e=this.poll();if(e!==undefined){if(this.debug){console.log("Run a Queued Function.")}e()}}function c(){this.debug=true}}var queue=new Queue();</script>

    <!-- Favicons -->
    <link rel="icon shortcut" type="image/ico" href="/img/favicon.png">
    <link rel="icon" sizes="192x192" href="/img/favicon.png">
    <link rel="apple-touch-icon" href="/img/favicon.png">

    <!--iOS -->
    <meta name="apple-mobile-web-app-title" content="Title">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="480">

    <!-- Add to homescreen for Chrome on Android -->
    <meta name="mobile-web-app-capable" content="yes">

    <!-- Add to homescreen for Safari on iOS -->
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="apple-mobile-web-app-title" content="0x2a">

    <!-- Site Verification -->
    
    

    <!-- RSS -->
    

    <!--[if lte IE 9]>
        <link rel="stylesheet" href="/css/ie-blocker.css">

        
            <script src="/js/ie-blocker.zhCN.js"></script>
        
    <![endif]-->

    <!-- Import CSS -->
    
        <style id="material_css"></style><script>if(typeof window.lsLoadCSSMaxNums === "undefined")window.lsLoadCSSMaxNums = 0;window.lsLoadCSSMaxNums++;lsloader.load("material_css","/css/material.min.css?Z7a72R1E4SxzBKR/WGctOA==",function(){if(typeof window.lsLoadCSSNums === "undefined")window.lsLoadCSSNums = 0;window.lsLoadCSSNums++;if(window.lsLoadCSSNums == window.lsLoadCSSMaxNums)document.documentElement.style.display="";}, false)</script>
        <style id="style_css"></style><script>if(typeof window.lsLoadCSSMaxNums === "undefined")window.lsLoadCSSMaxNums = 0;window.lsLoadCSSMaxNums++;lsloader.load("style_css","/css/style.min.css?MKetZV3cUTfDxvMffaOezg==",function(){if(typeof window.lsLoadCSSNums === "undefined")window.lsLoadCSSNums = 0;window.lsLoadCSSNums++;if(window.lsLoadCSSNums == window.lsLoadCSSMaxNums)document.documentElement.style.display="";}, false)</script>

        
            
                <style id="prettify_css"></style><script>if(typeof window.lsLoadCSSMaxNums === "undefined")window.lsLoadCSSMaxNums = 0;window.lsLoadCSSMaxNums++;lsloader.load("prettify_css","/css/prettify.min.css?KNukQf1VVhwBvp5icqaRFQ==",function(){if(typeof window.lsLoadCSSNums === "undefined")window.lsLoadCSSNums = 0;window.lsLoadCSSNums++;if(window.lsLoadCSSNums == window.lsLoadCSSMaxNums)document.documentElement.style.display="";}, false)</script>
                <style id="prettify_theme"></style><script>if(typeof window.lsLoadCSSMaxNums === "undefined")window.lsLoadCSSMaxNums = 0;window.lsLoadCSSMaxNums++;lsloader.load("prettify_theme","/css/prettify/atelier-cave-light.min.css?5MK/TK/zbpdHM7rmG+ehCw==",function(){if(typeof window.lsLoadCSSNums === "undefined")window.lsLoadCSSNums = 0;window.lsLoadCSSNums++;if(window.lsLoadCSSNums == window.lsLoadCSSMaxNums)document.documentElement.style.display="";}, false)</script>
            
        

    

    
        
            <link rel="stylesheet" href="/css/fontawesome.min.css">
        
    

    <!-- Config CSS -->

<!-- Other Styles -->
<style>
  body, html {
    font-family: Roboto, "Helvetica Neue", Helvetica, "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei", "微软雅黑", Arial, sans-serif;
    overflow-x: hidden !important;
  }
  
  code {
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  }

  a {
    color: #00838F;
  }

  .mdl-card__media,
  #search-label,
  #search-form-label:after,
  #scheme-Paradox .hot_tags-count,
  #scheme-Paradox .sidebar_archives-count,
  #scheme-Paradox .sidebar-colored .sidebar-header,
  #scheme-Paradox .sidebar-colored .sidebar-badge{
    background-color: #0097A7 !important;
  }

  /* Sidebar User Drop Down Menu Text Color */
  #scheme-Paradox .sidebar-colored .sidebar-nav>.dropdown>.dropdown-menu>li>a:hover,
  #scheme-Paradox .sidebar-colored .sidebar-nav>.dropdown>.dropdown-menu>li>a:focus {
    color: #0097A7 !important;
  }

  #post_entry-right-info,
  .sidebar-colored .sidebar-nav li:hover > a,
  .sidebar-colored .sidebar-nav li:hover > a i,
  .sidebar-colored .sidebar-nav li > a:hover,
  .sidebar-colored .sidebar-nav li > a:hover i,
  .sidebar-colored .sidebar-nav li > a:focus i,
  .sidebar-colored .sidebar-nav > .open > a,
  .sidebar-colored .sidebar-nav > .open > a:hover,
  .sidebar-colored .sidebar-nav > .open > a:focus,
  #ds-reset #ds-ctx .ds-ctx-entry .ds-ctx-head a {
    color: #0097A7 !important;
  }

  .toTop {
    background: #757575 !important;
  }

  .material-layout .material-post>.material-nav,
  .material-layout .material-index>.material-nav,
  .material-nav a {
    color: #757575;
  }

  #scheme-Paradox .MD-burger-layer {
    background-color: #757575;
  }

  #scheme-Paradox #post-toc-trigger-btn {
    color: #757575;
  }

  .post-toc a:hover {
    color: #00838F;
    text-decoration: underline;
  }

</style>


<!-- Theme Background Related-->

    <style>
      body{
        background-color: #F5F5F5;
      }

      /* blog_info bottom background */
      #scheme-Paradox .material-layout .something-else .mdl-card__supporting-text{
        background-color: #fff;
      }
    </style>




<!-- Fade Effect -->

    <style>
      .fade {
        transition: all 800ms linear;
        -webkit-transform: translate3d(0,0,0);
        -moz-transform: translate3d(0,0,0);
        -ms-transform: translate3d(0,0,0);
        -o-transform: translate3d(0,0,0);
        transform: translate3d(0,0,0);
        opacity: 1;
      }

      .fade.out{
        opacity: 0;
      }
    </style>


<!-- Import Font -->
<!-- Import Roboto -->

    <link href="https://fonts.proxy.ustclug.org/css?family=Roboto:300,400,500" rel="stylesheet">


<!-- Import Material Icon -->

    <link href="https://fonts.proxy.ustclug.org/icon?family=Material+Icons" rel="stylesheet">




    <!-- Import jQuery -->
    
        <script>lsloader.load("jq_js","/js/jquery.min.js?qcusAULNeBksqffqUM2+Ig==", true)</script>
    

    <!-- The Open Graph protocol -->
    <meta property="og:url" content="http://yoursite.com">
    <meta property="og:type" content="blog">
    <meta property="og:title" content="神经网络的简单理解 | 0x2a">
    <meta property="og:image" content="http://yoursite.com/img/favicon.png" />
    <meta property="og:description" content="">
    <meta property="og:article:tag" content="算法"> <meta property="og:article:tag" content="机器学习"> 

    
        <meta property="article:published_time" content="Wed Dec 05 2018 22:37:56 GMT+0800" />
        <meta property="article:modified_time" content="Thu Dec 06 2018 22:48:27 GMT+0800" />
    

    <!-- The Twitter Card protocol -->
    <meta name="twitter:title" content="神经网络的简单理解 | 0x2a">
    <meta name="twitter:description" content="">
    <meta name="twitter:image" content="http://yoursite.com/img/favicon.png">
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:url" content="http://yoursite.com" />

    <!-- Add canonical link for SEO -->
    
        <link rel="canonical" href="http://yoursite.com/2018/12/05/neural-network/index.html" />
    

    <!-- Structured-data for SEO -->
    
        


<script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "BlogPosting",
    "mainEntityOfPage": "http://yoursite.com/2018/12/05/neural-network/index.html",
    "headline": "神经网络的简单理解",
    "datePublished": "Wed Dec 05 2018 22:37:56 GMT+0800",
    "dateModified": "Thu Dec 06 2018 22:48:27 GMT+0800",
    "author": {
        "@type": "Person",
        "name": "Steve",
        "image": {
            "@type": "ImageObject",
            "url": "/img/avator.png"
        },
        "description": "Don't Panic."
    },
    "publisher": {
        "@type": "Organization",
        "name": "0x2a",
        "logo": {
            "@type":"ImageObject",
            "url": "/img/favicon.png"
        }
    },
    "keywords": ",算法,机器学习",
    "description": "",
}
</script>


    

    <!-- Analytics -->
    
    
    

    <!-- Custom Head -->
    

</head>


    
        <body id="scheme-Isolation" class="lazy">
            <div class="material-layout  mdl-js-layout has-drawer is-upgraded">
                
                    <!-- Isolation Header -->
                    <header class="header">
    <div class="header-wrapper">
        <!-- Header Copyright -->
        <div class="header-copyright">
            <div class="header-site">
                ©&nbsp;
                <script type="text/javascript">
                    var fd = new Date();
                    document.write(fd.getFullYear());
                </script>
                &nbsp;0x2a
            </div>
            <!--
            I'm gladd you use this theme, the development is no so easy, I hope you can keep the copyright.
            It will not impact the appearance and can give developers a lot of support :)

            很高兴您使用该主题，开发不易，希望您可以保留一下版权声明。
            它不会影响美观并可以给开发者很大的支持。 :)
            -->
            <div>
                Powered by <a href="https://hexo.io" target="_blank" class="footer-develop-a">Hexo</a>
                <br>
                Theme - <a href="https://github.com/viosey/hexo-theme-material" target="_blank" class="footer-develop-a">Material</a>
                <br>
                Hosted by <a href="https://pages.coding.me" target="_blank" class="footer-develop-a">Coding Pages</a>
            </div>
        </div>

        <!-- Header Title -->
        <span class="header-title header-item">
            <a href="/" title="0x2a">
                0x2a
            </a>
        </span>

        <p class="header-slogan header-item">
        
            
                Don't Panic.
            
        
        </p>

        <!-- Header Nav -->
        <nav class="header-nav header-item">
            <span class="header-nav-item">
                <a href="/" title="Home">
                    <span>主页</span>
                </a>
            </span>

            <!-- Pages  -->
            

        </nav>

        <!-- Header SNS -->
        <div class="header-item header-sns_list">
    <!-- Twitter -->
    

    <!-- Facebook -->
    

    <!-- Google + -->
    

    <!-- Weibo -->
    

    <!-- Instagram -->
    

    <!-- Tumblr -->
    

    <!-- Github -->
    
        <a href="https://github.com/Steve0x2a" target="_blank">
            <i class="fa fa-github fa-lg" aria-hidden="true"></i>
        </a>
    

    <!-- LinkedIn -->
    

    <!-- Telegram -->
    
</div>

    </div>
</header>

                

                <!-- Main Container -->
                <main class="material-layout__content" id="main">

                    <!-- Top Anchor -->
                    <div id="top"></div>

                    

                    <!-- Post TOC -->

    



<!-- Layouts -->

    <!-- Post Module -->
    <div class="material-post_container">

        <div class="material-post mdl-grid">
            <div class="mdl-card mdl-shadow--4dp mdl-cell mdl-cell--12-col">

                <!-- Post Header(Thumbnail & Title) -->
                


    <!-- Isolation Post Header -->
    <!-- Post thumbnail -->
    
        <!-- Post Header Info -->
        <div class="post-header_info without-thumbnail">
            <!-- Author Avatar & Name -->
            <img src="/img/avator.png" class="avatar-img" width="44px" height="44px" alt="Steve's avatar">
            <span class="name-span">Steve</span>
        </div>

        <!-- Null Thumbnail -->
        <div class="post_thumbnail-null">
    
        </div>



                

                <!-- Post Content -->
                <div id="post-content" class="mdl-color-text--grey-700 mdl-card__supporting-text fade out">
    

    
        <div class="post-content_wrapper">
            <p class="post-title">
                神经网络的简单理解
            </p>
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>好几个月没有写博文了, 感觉虚度了很多光阴. 最近在重新看吴恩达的&lt;机器学习&gt;, 相比于上次, 这次更多原理能看懂理解了, 这篇文章主要记录一下自己对神经网络的理解.</p>
<h1 id="为什么要神经网络"><a href="#为什么要神经网络" class="headerlink" title="为什么要神经网络"></a>为什么要神经网络</h1><p>在之前我们曾尝试过使用<code>Linear Regression</code>以及<code>Logistic Regression</code>来解决预测问题, 但是一旦我们的特征多了起来, 我们使用的多项式中的二项式的特征复杂度将士$O(N^2)$. 这样会导致过拟合以及计算资源耗费过大等问题. 当然我们也可以只使用到这些二次项的子集, 但是这必然带来了欠拟合的问题. 甚至更夸张的, 希望包括这些多项式的三次项, 复杂度就会高达$O(N^3) $</p>
<p>为了解决更复杂的预测 分类问题, 我们就需要用到神经网络.</p>
<h1 id="神经网络的基础"><a href="#神经网络的基础" class="headerlink" title="神经网络的基础"></a>神经网络的基础</h1><h2 id="神经网络表示"><a href="#神经网络表示" class="headerlink" title="神经网络表示"></a>神经网络表示</h2><p>神经网络建立在很多神经元上, 而每个神经元又是一个个学习模型.</p>
<p><img src="https://i.loli.net/2018/12/05/5c07f44d41e5d.jpg" alt=""></p>
<p>那我们结合多个神经元组成神经网络:</p>
<p><img src="https://i.loli.net/2018/12/05/5c07f467abfe4.jpg" alt=""></p>
<p>一些参数表示:</p>
<ul>
<li>$a^{(j)}_i$:第 $j$ 层的第$i​$个激活单元</li>
<li>$\theta^j_{ab}$ : 表示计算$j+1$层时第$a$项, 第$j$层第$b$项的参数</li>
<li>$\theta^{(j)}$ : 将第$j$层变成第$j+1$层的参数 </li>
<li>$L$ : layer总数目 上图 $L = 3$</li>
<li>$S_l$: 第l层由n个单位 如上图 $S_2=4$</li>
</ul>
<p>对于上图模型, 激活单元和输出可以表示为:</p>
<script type="math/tex; mode=display">
a _ { 1 } ^ { ( 2 ) } = g \left( \theta _ { 10 } ^ { ( 1 ) } x _ { 0 } + \theta _ { 11 } ^ { ( 1 ) } x _ { 1 } + \theta _ { 12 } ^ { ( 1 ) } x _ { 2 } + \theta _ { 13 } ^ { ( 1 ) } x _ { 3 } \right)</script><script type="math/tex; mode=display">
h _ { \theta } ( x ) = g \left( \theta _ { 10 } ^ { ( 2 ) } a _ { 0 } ^ { ( 2 ) } + \Theta _ { 11 } ^ { ( 2 ) } a _ { 1 } ^ { ( 2 ) } + \theta _ { 12 } ^ { ( 2 ) } a _ { 2 } ^ { ( 2 ) } + \theta _ { 13 } ^ { ( 2 ) } a _ { 3 } ^ { ( 2 ) } \right)</script><p>这样我们就可以根据公式, 将所有的训练集都喂给神经网络, 计算出所有的输出. 我们将这种从左到右的算法称为前向传播算法 <code>Forward Propagation</code></p>
<p>利用向量化的方法可以简化整个过程:</p>
<script type="math/tex; mode=display">
x = \left[ \begin{array} { c } { x _ { 0 } } \\ { x _ { 1 } } \\ { x _ { 2 } } \\ { x _ { 3 } } \end{array} \right] \quad z ^ { ( i) } = \left[ \begin{array} { c } { z _ { 1 } ^ { ( i ) } } \\ { z _ { 2 } ^ { ( i ) } } \\ { z _ { 3 } ^ { ( i ) } } \end{array} \right]</script><p>那么, 如果我们希望计算第二层的的值, 可以:</p>
<script type="math/tex; mode=display">
\begin{aligned} z ^ { ( 2 ) } & = \Theta ^ { ( 1 ) } x \\ a ^ { ( 2 ) } & = g \left( z ^ { ( 2 ) } \right) \end{aligned}</script><p>将其展开则为:</p>
<p><img src="https://i.loli.net/2018/12/06/5c0936a727d8c.jpg" alt=""></p>
<p>令 $z ^ { ( 2 ) } = \theta ^ { ( 1 ) } x$ 则 $a ^ { ( 2 ) } = g \left( z ^ { ( 2 ) } \right)$ 并且加上bias unit: $a _ { 0 } ^ { ( 2 ) } = 1$ 计算输出值</p>
<script type="math/tex; mode=display">
g \left( \left[ \begin{array} { c c c } { \theta _ { 10 } ^ { ( 2 ) } } & { \theta _ { 11 } ^ { ( 2 ) } } & { \theta _ { 12 } ^ { ( 2 ) } } & { \theta _ { 13 } ^ { ( 2 ) } ] \times \left| \begin{array} { c } { u _ { 0 } } \\ { a _ { 1 } ^ { ( 2 ) } } \\ { a _ { 2 } ^ { ( 2 ) } } \\ { a _ { 3 } ^ { ( 2 ) } } \end{array}  \right] \Bigg) = g \left( \theta _ { 10 } ^ { ( 2 ) } a _ { 0 } ^ { ( 2 ) } + \theta _ { 11 } ^ { ( 2 ) } a _ { 1 } ^ { ( 2 ) } + \theta _ { 12 } ^ { ( 2 ) } a _ { 2 } ^ { ( 2 ) } + \theta _ { 13 } ^ { ( 2 ) } a _ { 3 } ^ { ( 2 ) } \right) = h _ { \theta } ( x ) } \end{array} \right.\right.</script><p>又$z ^ { ( 3 ) } = \theta ^ { ( 2 ) } a ^ { ( 2 ) }$, 则 $h _ { \theta } ( x ) = a ^ { ( 3 ) } = g \left( z ^ { ( 3 ) } \right)$</p>
<p>以上只是针对某个训练样本, 但是我们需要针对整个样本进行计算. 我们需要将训练集特征矩阵进行转置，使得同一个实例的特征都在同一列里。即：</p>
<script type="math/tex; mode=display">
\begin{array} { l } { z ^ { ( 2 ) } = \theta ^ { ( 1 ) } \times X ^ { T } } \\ { a ^ { ( 2 ) } = g \left( z ^ { ( 2 ) } \right) } \end{array}</script><p>一个传统的神经网络就可以看成多个<code>Logistic Regression</code>模型的输出作为另一个<code>Logistic Regression</code>模型的输入的“组合模型”。其实神经网络的底层思想和<code>Logistic Regression</code>很相似, 我们只保留输出层和最后一个隐藏层:</p>
<p><img src="https://i.loli.net/2018/12/06/5c07faded4159.jpg" alt=""></p>
<p>那么此时神经网络就只剩一个<code>Logistic Regression</code>了:</p>
<script type="math/tex; mode=display">
h _ { \theta } ( x ) = g \left( \theta _ { 0 } ^ { ( 2 ) } a _ { 0 } ^ { ( 2 ) } + \theta _ { 1 } ^ { ( 2 ) } a _ { 1 } ^ { ( 2 ) } + \theta _ { 2 } ^ { ( 2 ) } a _ { 2 } ^ { ( 2 ) } + \theta _ { 3 } ^ { ( 2 ) } a _ { 3 } ^ { ( 2 ) } \right)</script><p>我们可以把$a _ { 0 } , a _ { 1 } , a _ { 2 } , a _ { 3 }$看作更高级的的特征, 但是他们还是由$x_i$决定的. 这些高级特征值比仅仅用$x_i$用作预测有效果, 这也是神经网络比线性回归更有效的原因之一.</p>
<h2 id="偏置的作用"><a href="#偏置的作用" class="headerlink" title="偏置的作用"></a>偏置的作用</h2><p>偏置项让神经网络更加灵活, 更容易收敛.  我们来看一个比较简单的例子: 考虑一个只有一个输入以及一个输出(没有bias unit)的网络.</p>
<p><img src="https://i.loli.net/2018/12/06/5c081e5c61fa2.jpg" alt=""></p>
<p>那么这个网络的输出经过权重<code>w0</code>的计算以及激活函数(如sigmoid函数)后, 输出如图所示:</p>
<p><img src="https://i.loli.net/2018/12/06/5c081ec07b286.jpg" alt=""></p>
<p>我们修改$w_0$的值可以改变函数的陡峭程度, 但是如果我们的输入$x_i=1$时 要求输出$y_o$为2时, 无论我们怎么修改$w_0$, 也无法达成要求.  我们希望整个函数图像可以向右移动, 这样就可以满足要求了.</p>
<p>这就是bias unit的作用:</p>
<p><img src="https://i.loli.net/2018/12/06/5c081f966dbe8.jpg" alt=""></p>
<p>当我们添加一个bias unit 以及他也有自己的$weight$, 我们的输出就变成了$sigmoid(w_0 <em>x + w_1 </em> 1)$ 如图:</p>
<p><img src="https://i.loli.net/2018/12/06/5c0820039d89d.jpg" alt=""></p>
<p>这样, 红色线就能满足我们的要求: $x = 2$时$y_o = 0 $ .</p>
<h2 id="多分类"><a href="#多分类" class="headerlink" title="多分类"></a>多分类</h2><p>上述的神经网络都是只有单个输出, 只能用于而分类问题. 当我们需要使用神经网络解决多分类问题时, 需要进行一定的处理.</p>
<p><img src="https://i.loli.net/2018/12/06/5c08adace7780.jpg" alt=""></p>
<p>如上图, 可能的输出为: </p>
<script type="math/tex; mode=display">
\left[ \begin{array} { l } { 1 } \\ { 0 } \\ { 0 } \\ { 0 } \end{array} \right] , \left[ \begin{array} { l } { 0 } \\ { 1 } \\ { 0 } \\ { 0 } \end{array} \right] , \left[ \begin{array} { l } { 0 } \\ { 0 } \\ { 1 } \\ { 0 } \end{array} \right] , \left[ \begin{array} { l } { 0 } \\ { 0 } \\ { 0 } \\ { 1 } \end{array} \right]</script><p>四种情况分别对应一种结果.</p>
<h1 id="神经网络的学习"><a href="#神经网络的学习" class="headerlink" title="神经网络的学习"></a>神经网络的学习</h1><h2 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h2><p>先回顾一下<code>Logistic Regression</code>的<code>Cost Function</code>:</p>
<script type="math/tex; mode=display">
J ( \theta ) = - \frac { 1 } { m } \left[ \sum _ { j = 1 } ^ { n } y ^ { ( i ) } \log h _ { \theta } \left( x ^ { ( i ) } \right) + \left( 1 - y ^ { ( i ) } \right) \log \left( 1 - h _ { \theta } \left( x ^ { ( i ) } \right) \right) \right] + \frac { \lambda } { 2 m } \sum _ { j = 1 } ^ { n } \theta _ { j } ^ { 2 }</script><p>然而, 在<code>Logistic Regression</code>中我们只有一个输出变量, 但是在神经网络中, 我们由很多输出变量:</p>
<script type="math/tex; mode=display">
 h _ { \theta } ( x ) \in \mathbb { R } ^ { K } , \left( h _ { \theta } ( x ) \right) _ { i } = i ^ { t h }output</script><script type="math/tex; mode=display">
J ( \Theta ) = - \frac { 1 } { m } \left[ \sum _ { i = 1 } ^ { m } \sum _ { k = 1 } ^ { k } y _ { k } ^ { ( i ) } \log \left( h _ { \mathrm { o } } \left( x ^ { ( i ) } \right) \right) _ { k } + \left( 1 - y _ { k } ^ { ( i ) } \right) \log \left( 1 - \left( h _ { \mathrm { e } } \left( x ^ { ( i ) } \right) \right) _ { k } \right) \right]++ \frac { \lambda } { 2 m } \sum _ { l = 1 } ^ { L - 1 } \sum _ { j = 1 } ^ { s _ { l } } \sum _ { j = 1 } ^ { s _ { 1 } + 1 } \left( \Theta _ { j i } ^ { ( l ) } \right) ^ { 2 }</script><p>看起来比<code>Logistic Regression</code>回归复杂了很多, 但是背后的思想是一样的: 我们希望通过<code>Cost Function</code>来衡量我们当前预测结果和真实情况的误差有多大, 相比于<code>Logistic Regression</code>, 由于神经网络有多个输出值, 我们需要选出可能性在最高的那个与我们的实际值进行比较.</p>
<h2 id="反向传播算法"><a href="#反向传播算法" class="headerlink" title="反向传播算法"></a>反向传播算法</h2><p>为了根据我们训练集的输出误差来调整整个网络的权值, 我们可以使用一种叫做反向传播的算法. 对应前面所说的用于计算输出值的正向传播, 反向传播可以计算最后一层的误差, 然后再一层一层反向求出各层的误差, 直到倒数第二层, 进而改变相关的参数.</p>
<p>一开始看反向传播算法觉得一头雾水, 直到看到了<a href="https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/" target="_blank" rel="noopener">A Step by Step Backpropagation Example</a>这篇博文, 才直观地感受到了反向传播的整体意义. 记录一下这篇文章对反向传播过程的推导.</p>
<p>假设我们有以下神经网络:</p>
<p><img src="https://i.loli.net/2018/12/06/5c08b4b3a158d.jpg" alt=""></p>
<p>第一层是输入层, 有两个输入神经元$i_1, i_2$ 同时包括一个偏置项$b_1$; 第二层是隐含层, 包含神经元$h_1,h_2$以及偏置项$b_2$; 第三层是输出层$o_1, o_2$.  初始化一组权值：</p>
<p><img src="https://i.loli.net/2018/12/06/5c0909d35f610.png" alt=""></p>
<p>我们的目标是调整神经网络的权值，以保证输出可以尽可能拟合我们的实际值。在图片的例子中，我们希望输入是0.05 0.1时 输出是0.01和0.99。</p>
<h3 id="1-前向传播："><a href="#1-前向传播：" class="headerlink" title="1. 前向传播："></a>1. 前向传播：</h3><p>对于$h_1$有：</p>
<script type="math/tex; mode=display">net_{h1}=w_i * i_1 + w_2 * i_2 +b_1 * 1</script><p>既：</p>
<script type="math/tex; mode=display">net_h1 = 0.15*0.05 + 0.2 * 0.1 + 0.35 * 1 = 0.3775</script><p> 再将$h_1$经过<code>sigmoid</code>函数就可以算出$out_{h1}$:</p>
<script type="math/tex; mode=display">out_{h1} = \frac{1}{1+e^{-net_{h1}}} = 0.5932</script><p>同理可以计算出$out_{h2} = 0.5968$.<br>$o_1$是由两个项决定的：</p>
<script type="math/tex; mode=display">net_{o1} = w5*out_{h1} + w6 * out_{h2} + b_2 *1</script><script type="math/tex; mode=display">out_{o1} = \frac{1}{1+e^{-net_{o1}}} = 0.7513</script><p>同理， $out_{o2} = 0.7729$</p>
<h3 id="2-计算总误差"><a href="#2-计算总误差" class="headerlink" title="2. 计算总误差"></a>2. 计算总误差</h3><p>我们这样定义总误差<code>Squared Error</code>:</p>
<script type="math/tex; mode=display">E_total = \sum \frac{1}{2}(target - output)^2</script><p>其中<code>target</code>是我们计算出的预测值，<code>output</code>是数据集实际值。（有些资料会用<code>ideal</code>代表<code>target</code>，<code>actual</code>代表<code>output</code>）</p>
<script type="math/tex; mode=display">E_{o1}=\frac{1}{2}(0.01-0.7513)^2=0.2748</script><p>同理可以算出$a$。所以:</p>
<script type="math/tex; mode=display">
E_{total} = E_{o1}+E_{o2}= 0.2748+0.0235 = 0.2983</script><h3 id="3-反向传播"><a href="#3-反向传播" class="headerlink" title="3. 反向传播"></a>3. 反向传播</h3><p>我们希望先探讨一下$w_5$对于<code>Total Error</code>的影响，那么很容易想到我们可以求偏导：$\frac{\partial{E_{total}}}{\partial{w5}}$</p>
<p>根据链式法则：<br><img src="https://i.loli.net/2018/12/06/5c0909d35f51e.png" alt=""></p>
<script type="math/tex; mode=display">
\frac { \partial E _ { \text { total } } } { \partial w _ { 5 } } = \frac { \partial E _ { \text { total } } } { \partial \text {out} _ { o 1 } }  * \frac { \partial o u t _ { o 1 } } { \partial n e t _ { o 1 } } * \frac { \partial n e t _ { o 1 } } { \partial w _ { 5 } }</script><p>在本例中：</p>
<script type="math/tex; mode=display">
E _ { t o t a l } = \frac { 1 } { 2 } \left( t a r g e t _ { o 1 } - o u t _ { o 1 } \right) ^ { 2 } + \frac { 1 } { 2 } \left( \operatorname { target } _ { o 2 } - o u t _ { o 2 } \right) ^ { 2 } \\
\frac { \partial E _ { \text { total } } } { \partial \text { out } _ { \text { ol } } } = 2 * \frac { 1 } { 2 } \left( \text {target} _ { o 1 } - o u t _ { o 1 } \right) ^ { 2 - 1 } * - 1 + 0 = = - \left( \text { target } _ { o 1 } - o u t _ { o 1 } \right)\\
\frac { \partial E _ { \text { total } } } { \partial \text { out ol } } = - \left( \text { target } _ { o 1 } - o u t _ { o 1 } \right) = - ( 0.01 - 0.75136507 ) = 0.74136507</script><p>根据链式法则继续往下算:</p>
<script type="math/tex; mode=display">
o u t _ { o 1 } = \frac { 1 } { 1 + e ^ { - n c t _ { 01 } } }\\
\frac { \partial \text {outol} } { \partial n e t _ { 01 } } = o u t _ { o 1 } \left( 1 - o u t _ { o 1 } \right) = 0.75136507( 1 - 0.75136507 ) = 0.186815602</script><p>最后可以计算出$w_{5}$对$o_{1}$的影响:</p>
<script type="math/tex; mode=display">
\begin{array} { l } { n e t _ { o 1 } = w _ { 5 } * o u t _ { h 1 } + w _ { 6 } * o u t _ { h 2 } + b _ { 2 } * 1 } \\ { \frac { \partial n e t _ { o 1 } } { \partial w _ { 5 } } = 1 * o u t _ { h 1 } * w _ { 5 } ^ { ( 1 - 1 ) } + 0 + 0 = o u t _ { h 1 } = 0.593269992 } \end{array}</script><p>将他们整合起来:</p>
<script type="math/tex; mode=display">
\frac { \partial E _ { \text { total } } } { \partial w _ { 5 } } = \frac { \partial E _ { \text { total } } } { \partial \text {out} _ { \text { ol } } } *\frac { \partial \text {out} _ { 01 } } { \partial n e t _ { o 1 } }*\frac { \partial n e t _ { 01 } } { \partial w _ { 5 } } \\
\frac { \partial E _ { t a t al} } { \partial w _ { 5 } } = 0.74136507 * 0.186815602 * 0.5932699992 = 0.082167041</script><blockquote>
<p>我们常常使用$\delta _{o1}$来表示输出层的误差:</p>
<script type="math/tex; mode=display">\delta _ { o 1 } = \frac { \partial E _ { \text { total } } } { \partial o u t _ { o1 } } * \frac { \partial \text {out} _ { 01 } } { \partial n e t _ { o 1 } } =\frac { \partial E _ { t o t a l } } { \partial r e t _ { o 1 } } \\ \delta _ { o 1 } = - \left( \operatorname { target } _ { o 1 } - o u t _ { o 1 } \right) * o u t _ { o 1 } \left( 1 - o u t _ { o 1 } \right)</script><p>所以:</p>
<p>$\frac { \partial E _ { \text { total } } } { \partial w _ { 5 } } = \delta _ { o 1 } out _ { h 1 }$</p>
</blockquote>
<p>求得$w_{5}$对$E_{total}$的影响后, 就可以更新$w_{5}$了:</p>
<script type="math/tex; mode=display">
w _ { 5 } ^ { + } = w _ { 5 } - \eta * \frac { \partial E _ { \text { total } } } { \partial w _ { 5 } } = 0.4 - 0.5 * 0.082167041 = 0.35891648</script><p>其中$\eta$是学习率 <code>Learning rate</code>, 有些资料也会用 $\alpha$ 或 $\epsilon$ 表示.</p>
<p>同样的我们可以更新$w_{6},w_{7},w_{8}$值.</p>
<p>在更新完输出层的权值后, 我们开始计算隐藏层的权值</p>
<p><img src="https://i.loli.net/2018/12/06/5c0916f648f27.jpg" alt=""></p>
<p>比如我们需要计算$w_{1}$对$E_{\text{total}}$的影响:</p>
<script type="math/tex; mode=display">
\frac { \partial E _ { \text { total } } } { \partial w _ { 1 } } = \frac { \partial E _ { \text { total } } } { \partial o u t _ { h 1 } } * \frac { \partial \omega u t _ { h 1 } } { \partial n e t _ { h 1 } } * \frac { \partial n e t _ { h 1 } } { \partial w _ { 1 } }</script><p>从上图可知, $\frac { \partial E _ { \text { total } } } { \partial \text {out} _ { h 1 } }$由两部分组成:</p>
<script type="math/tex; mode=display">
\frac { \partial E _ { \text { otal } } } { \partial o u t _ { h 1 } } = \frac { \partial E _ { o 1 } } { \partial o u t _ { h 1 } } + \frac { \partial E _ { o 2 } } { \partial o u t _ { h 1 } }</script><p>接下来计算$\frac { \partial E _ { o 1 } } { \partial \omega u t _ { h 1 } }$:</p>
<script type="math/tex; mode=display">
\frac { \partial E _ { o 1 } } { \partial o u t _ { h 1 } } = \frac { \partial E _ { o 1 } } { \partial n e t _ { o 1 } } * \frac { \partial n e t _ { o 1 } } { \partial o u t _ { h 1 } }</script><p>$\frac { \partial E _ { o 1 } } { \partial n e t _ { o 1 } }$使用之前计算过的数据可以直接求得:</p>
<script type="math/tex; mode=display">
\frac { \partial E _ { o 1 } } { \partial n e t _ { o 1 } } = \frac { \partial E _ { o 1 } } { \partial o u t _ { o 1 } }* \frac { \partial o u t o _ { 1 } } { \partial n e t _ { o 1 } } = 0.74136507 * 0.186815602 = 0.138498562</script><p>同时 容易证明$\frac { \partial n e t _ { 0 } 1 } { \partial \omega u t _ { h 1 } } = u _ { 5 }$</p>
<script type="math/tex; mode=display">
\begin{array} { l } { n e t _ { o 1 } = w _ { 5 } * o u t _ { h 1 } + w _ { 6 } * o u t _ { h 2 } + b _ { 2 } * 1 } \\ { \frac { \partial n e t _ { o 1 } } { \partial o u t _ { h 1 } } = w _ { 5 } = 0.40 } \end{array}</script><p>将计算出来的值代回原式计算:</p>
<script type="math/tex; mode=display">
\frac { \partial E _ { o 1 } } { \partial o u t _ { h 1 } } = \frac { \partial E _ { o 1 } } { \partial n e t _ { o 1 } } * \frac { \partial n e t _ { o 1 } } { \partial o u t _ { h 1 } } = 0.138498562 * 0.40 = 0.055399425</script><p>同理可计算出:</p>
<script type="math/tex; mode=display">
\frac { \partial E _ { o 2 } } { \partial o u t _ { h 1 } } = - 0.019049119</script><p>因此:</p>
<script type="math/tex; mode=display">
\frac { \partial E _ { \text {total} } } { \partial o u t _ { h 1 } } = \frac { \partial E _ { \mathrm { ol } } } { \partial o u t _ { h 1 } } + \frac { \partial E _ { o 2 } } { \partial o u t _ { h 1 } } = 0.055399425 + - 0.019049119 = 0.036350306</script><p>现在我们已经有了$\frac { \partial E _ { \text {total} } } { \partial o u t _ { h 1 } }$, 我们需要计算出$\frac { \partial o u t _ { h 1 } } { \partial n e t _ { h 1 } }$ 然后计算出每个$w$对$net_{h1}$的影响:</p>
<script type="math/tex; mode=display">
\begin{aligned} o u t _ { h 1 } & = \frac { 1 } { 1 + e ^ { - n c t / h 1 } } \\ \frac { \partial o u t _ { h 1 } } { \partial n e t _ { h 1 } } & = o u t _ { h 1 } \left( 1 - o u t _ { h 1 } \right) = 0.59326999 ( 1 - 0.59326999 ) = 0.241300709 \end{aligned}</script><p>又:</p>
<script type="math/tex; mode=display">
\begin{array} { l } { n e t _ { h 1 } = w _ { 1 } * i _ { 1 } + w _ { 3 } * i _ { 2 } + b _ { 1 } * 1 } \\ { \frac { \partial n e t _ { h 1 } } { \partial w _ { 1 } } = i _ { 1 } = 0.05 } \end{array}</script><p>将他们代入原式计算:</p>
<script type="math/tex; mode=display">
\frac { \partial E _ { \text { total } } } { \partial w _ { 1 } } = \frac { \partial E _ { \text { total } } } { \partial o u t _ { h 1 } } *\frac { \partial o u t _ { h 1 } } { \partial n e t _ { h 1 } } * \frac { \partial n e t _ { h 1 } } { \partial z _ { 1 } }\\ \frac { \partial E _ { \text { total } } } { \partial w _ { 1 } } = 0.036350306 * 0.241300709 * 0.05 = 0.000438568</script><p> 现在我们就可以更新隐藏层的权值:</p>
<script type="math/tex; mode=display">
w _ { 1 } ^ { + } = w _ { 1 } - \eta * \frac { \partial E _ { \text {total} } } { \partial w _ { 1 } } = 0.15 - 0.5 * 0.000438568 = 0.149780716</script><p>同样的我们也可以这样更新$w_{2},w_{3},w_{4}$</p>
<p>到此 一个循环的反向传播算法已经结束, 利用多次迭代, 就可以将权值更新到一个可以使输出较为准确的数值, 这就是反向传播的基本思想.</p>
<h1 id="后话"><a href="#后话" class="headerlink" title="后话"></a>后话</h1><p>总算把一直没有怎么认真看的神经网络给啃了, 当然这里面的只是涉及到神经网络的一些很基本的理论, 看有没有时间再更一篇比较跟得上时代的神经网络文章吧. </p>
<p>以及, 一步步推导公式还是很有意思的, 虽然打latex公式还是很累. 顺便安利一下<a href="https://mathpix.com/" target="_blank" rel="noopener">Mathpix</a> 这款软件, 省了我不少打公式的时间!!!</p>

            
        </div>
    
</div>


                
                    <!-- Paradox Post Info -->
                    
                

                <!-- Post Comments -->
                
                    
    <!-- 使用 来必力 -->
<div id="livere-comment">
    <div id="lv-container" data-id="city" data-uid="MTAyMC8zODY4MS8xNTIwOQ=="></div>
<script type="text/javascript">
 (function(d, s) {
     var j, e = d.getElementsByTagName(s)[0];

     if (typeof LivereTower === 'function') { return; }

     j = d.createElement(s);
     j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
     j.async = true;

     e.parentNode.insertBefore(j, e);
 })(document, 'script');
</script>

</div>
<style>
    #livere-comment{
        background-color: #eee;
        padding: 2pc;
    }
</style>

                
            </div>

            <!-- Post Prev & Next Nav -->
            <nav class="material-nav mdl-color-text--grey-50 mdl-cell mdl-cell--12-col">
    <!-- Prev Nav -->
    

    <!-- Section Spacer -->
    <div class="section-spacer"></div>

    <!-- Next Nav -->
    
        <a href="/2018/08/07/linear_algebra_1/" id="post_nav-older" class="next-content">
            旧篇
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <button class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon mdl-color--white mdl-color-text--grey-900" role="presentation">
                <i class="material-icons">arrow_forward</i>
            </button>
        </a>
    
</nav>

        </div>
    </div>



                    

                    

                    <!--Footer-->
<footer class="mdl-mini-footer" id="bottom">
    
</footer>


                    <!-- Import JS File -->

    <script>lsloader.load("lazyload_js","/js/lazyload.min.js?1BcfzuNXqV+ntF6gq+5X3Q==", true)</script>



    <script>lsloader.load("js_js","/js/js.min.js?V/53wGualMuiPM3xoetD5Q==", true)</script>



    <script>lsloader.load("np_js","/js/nprogress.js?pl3Qhb9lvqR1FlyLUna1Yw==", true)</script>


<script type="text/ls-javascript" id="NProgress-script">
    NProgress.configure({
        showSpinner: true
    });
    NProgress.start();
    $('#nprogress .bar').css({
        'background': '#29d'
    });
    $('#nprogress .peg').css({
        'box-shadow': '0 0 10px #29d, 0 0 15px #29d'
    });
    $('#nprogress .spinner-icon').css({
        'border-top-color': '#29d',
        'border-left-color': '#29d'
    });
    setTimeout(function() {
        NProgress.done();
        $('.fade').removeClass('out');
    }, 800);
</script>









   





<!-- UC Browser Compatible -->
<script>
	var agent = navigator.userAgent.toLowerCase();
	if(agent.indexOf('ucbrowser')>0) {
		document.write('<link rel="stylesheet" href="/css/uc.css">');
	   alert('由于 UC 浏览器使用极旧的内核，而本网站使用了一些新的特性。\n为了您能更好的浏览，推荐使用 Chrome 或 Firefox 浏览器。');
	}
</script>

<!-- Import prettify js  -->

    
        
            <script>lsloader.load("prettify_js","/js/prettify.min.js?WN07fivHQSMKWy7BmHBB6w==", true)</script>
        
    



<!-- Window Load -->
<!-- add class for prettify -->
<script type="text/ls-javascript" id="window-load">
    $(window).on('load', function() {
        // Post_Toc parent position fixed
        $('.post-toc-wrap').parent('.mdl-menu__container').css('position', 'fixed');
    });

    
        
            $(function() {
                $('pre').addClass('prettyprint linenums').attr('style', 'overflow:auto;');
                prettyPrint();
                })
        
    
    
</script>

<!-- MathJax Load-->

    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"], linebreaks: { automatic:true }, EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50) },
        tex2jax: { inlineMath: [ ["$", "$"], ["\\(","\\)"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno",skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']},
        TeX: {  noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } }, Macros: { href: "{}" } },
        messageStyle: "none"
    });
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

    <script src="https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>




<!-- Bing Background -->


<script type="text/ls-javascript" id="lazy-load">
    // Offer LazyLoad
    queue.offer(function(){
        $('.lazy').lazyload({
            effect : 'show'
        });
    });

    // Start Queue
    $(document).ready(function(){
        setInterval(function(){
            queue.execNext();
        },200);
    });
</script>

<!-- Custom Footer -->



<script>
    (function(){
        var scriptList = document.querySelectorAll('script[type="text/ls-javascript"]')

        for (var i = 0; i < scriptList.length; ++i) {
            var item = scriptList[i];
            lsloader.runInlineScript(item.id,item.id);
        }
    })()
console.log('\n %c © Material Theme | Version: 1.5.0 | https://github.com/viosey/hexo-theme-material %c \n', 'color:#455a64;background:#e0e0e0;padding:5px 0;border-top-left-radius:5px;border-bottom-left-radius:5px;', 'color:#455a64;background:#e0e0e0;padding:5px 0;border-top-right-radius:5px;border-bottom-right-radius:5px;');
</script>

                </main>
            </div>
        </body>
    
</html>
